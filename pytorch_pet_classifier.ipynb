{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import os\n",
    "import re as regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './images'\n",
    "batch_size = 32\n",
    "filenames = glob('./images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename) :\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "classes = set()\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load the images and get the classnames from the image path\n",
    "for image in filenames:\n",
    "    class_name = regex.findall(r'(.+)_\\d+.jpg$', image)[0]\n",
    "    classes.add(class_name)\n",
    "    img = load_image(image)\n",
    "\n",
    "    data.append(img)\n",
    "    labels.append(class_name)\n",
    "\n",
    "# convert classnames to indices\n",
    "class2idx = {cl: idx for idx, cl in enumerate(classes)}        \n",
    "labels = torch.Tensor(list(map(lambda x: class2idx[x], labels))).long()\n",
    "\n",
    "data = list(zip(data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesLoader(DataLoader):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.len = len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.data[index]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data is not split into train and validation datasets we have to \n",
    "# make sure that when splitting between train and val that all classes are represented in both\n",
    "class Databasket():\n",
    "    \"Helper class to ensure equal distribution of classes in both train and validation datasets\"\n",
    "    \n",
    "    def __init__(self, data, num_cl, val_split=0.2, train_transforms=None, val_transforms=None):\n",
    "        class_values = [[] for x in range(num_cl)]\n",
    "        \n",
    "        # create arrays for each class type\n",
    "        for d in data:\n",
    "            class_values[d[1].item()].append(d)\n",
    "            \n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "        \n",
    "        # put (1-val_split) of the images of each class into the train dataset\n",
    "        # and val_split of the images into the validation dataset\n",
    "        for class_dp in class_values:\n",
    "            split_idx = int(len(class_dp)*(1-val_split))\n",
    "            self.train_data += class_dp[:split_idx]\n",
    "            self.val_data += class_dp[split_idx:]\n",
    "            \n",
    "        self.train_ds = ImagesLoader(self.train_data, transform=train_transforms)\n",
    "        self.val_ds = ImagesLoader(self.val_data, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply transformations to the train dataset\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "# apply the same transformations to the validation set, with the exception of the\n",
    "# randomized transformation. We want the validation set to be consistent\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "databasket = Databasket(data, len(classes), val_split=0.2, train_transforms=train_transforms, val_transforms=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12 * 55 * 55, out_features=110)\n",
    "        self.fc2 = nn.Linear(in_features=110, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=37)\n",
    "\n",
    "    def forward(self, t):\n",
    "                # : torch.Tensor) -> torch.Tensor:\n",
    "        t = t\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2)\n",
    "\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2)\n",
    "        # Before we pass our input to the first hidden linear layer, we must reshape() or flatten our tensor. \n",
    "        # This will be the case any time we are passing output from a convolutional layer as input to a linear layer.\n",
    "        t = t.reshape(-1, 12 * 55 *55)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        t = F.softmax(t)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(range(len(databasket.train_ds)))\n",
    "test_indices = list(range(len(databasket.val_ds)))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# Basic dataloader to retrieve mini-batches from the datasets\n",
    "train_loader = DataLoader(databasket.train_ds, batch_size=64, sampler=train_sampler, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(databasket.val_ds, batch_size=64, sampler=test_sampler, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "  for epoch in range(5):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # total_correct += get_num_correct(preds, labels)\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "  \n",
    "    train_acc = 100. * total_correct / len(databasket.train_ds)\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    print('Epoch %s: Train Accuracy: %.2f percent, Train Loss: %s' \n",
    "              % (epoch, train_acc, train_loss))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff2c55019121a2c56cd7cb35a74771268e9f84077a0dddc424ec74d5925bffdf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
